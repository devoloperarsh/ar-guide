<!DOCTYPE html>
<html>
<head>
  <title>AR AI Friend</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link href="https://fonts.googleapis.com/css2?family=Nunito:wght@700&display=swap" rel="stylesheet">
  <script src="https://aframe.io/releases/1.4.2/aframe.min.js"></script>
  <script src="https://cdn.jsdelivr.net/gh/AR-js-org/AR.js/aframe/build/aframe-ar.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/aframe-extras@6.1.1/dist/aframe-extras.min.js"></script>
  <style>
    body {
      margin: 0;
      overflow: hidden;
      background: linear-gradient(135deg,#4f84ff 0%, #dca7ff 100%);
      font-family: 'Nunito', sans-serif;
    }
    /* #ui removed for single mic button only */ #ui {
      position: fixed;
      width: 100vw;
      max-width: 100vw;
      min-width: 0;
      left: 0;
      bottom: 0;
      display: flex;
      flex-direction: column;
      align-items: center;
      gap: 4vw;
      z-index: 7;
      background: rgba(255,255,255,0.12);
      padding-top: 4vw;
      padding-bottom: 4vw;
      box-shadow: 0 -6px 32px #2223;
      border-top-left-radius: 4vw;
      border-top-right-radius: 4vw;
    }
    #mic {
      background: linear-gradient(135deg,#36d1c4,#5b86e5);
      color: white;
      border: none;
      font-size: 7vw;
      border-radius: 50vw;
      width: 18vw;
      height: 18vw;
      max-width: 90px;
      max-height: 90px;
      min-width: 52px;
      min-height: 52px;
      box-shadow: 0 6px 32px #2edab233;
      display: flex;
      align-items: center;
      justify-content: center;
      transition: box-shadow 0.15s, background 0.15s;
      cursor: pointer;
      outline: none;
      margin-bottom: 1vw;
      touch-action: manipulation;
    }
    #mic.recording {
      background:linear-gradient(135deg,#ea447a,#ff6c33);
      box-shadow: 0 6px 32px #ff4a6380;
      animation: pulse 1s infinite;
    }
    @keyframes pulse {
      0% { box-shadow: 0 0 0 0 #ff4a6380; }
      70% { box-shadow: 0 0 0 20px #ff4a6300; }
      100% { box-shadow: 0 0 0 0 #ff4a6300; }
    }
    #status, #ai-response {
      color: #fff;
      background:rgba(0,0,0,0.22);
      border-radius:4vw;
      padding:2vw 5vw 2vw 5vw;
      font-size:4vw;
      max-width:86vw;
      margin:auto;
      word-break: break-word;
      box-sizing: border-box;
      line-height:1.6em;
    }
    #ai-response {
      font-size:5vw;
      color:#ffe47a;
      margin-bottom:2vw;
    }
  </style>
</head>
<body>

<a-scene arjs="sourceType: webcam;" vr-mode-ui="enabled: false" renderer="logarithmicDepthBuffer: true;">
  <a-marker preset="hiro" id="ar-marker">
    <a-entity id="idle" gltf-model="friend_idle.glb" scale="0.5 0.5 0.5" rotation="0 180 0" visible="true" animation-mixer persistent-avatar></a-entity>
    <a-entity id="talk" gltf-model="friend_talk.glb" scale="0.5 0.5 0.5" rotation="0 180 0" visible="false" animation-mixer persistent-avatar></a-entity>
  </a-marker>
  <a-entity camera></a-entity>
</a-scene>

<button id="mic" onclick="startListening()" style="
  position: fixed;
  left: 50%;
  bottom: 4vw;
  transform: translateX(-50%);
  z-index: 10;
  background: linear-gradient(135deg,#36d1c4,#5b86e5);
  color: white;
  border: none;
  font-size: 7vw;
  border-radius: 50vw;
  width: 18vw;
  height: 18vw;
  max-width: 90px;
  max-height: 90px;
  min-width: 52px;
  min-height: 52px;
  display: flex;
  align-items: center;
  justify-content: center;
  transition: box-shadow 0.15s, background 0.15s;
  cursor: pointer;
  outline: none;
  touch-action: manipulation;
">
  <span id="mic-emoji">ðŸŽ¤</span>
</button>

<script>
AFRAME.registerComponent('persistent-avatar', {
  init: function () {
    this.placed = false;
    this.marker = this.el.parentEl;
    const avatar = this.el;
    // Helper: move this entity to world root at given world transform
    this.placeInWorld = (pos, rot, scale) => {
      const scene = avatar.sceneEl;
      avatar.object3D.position.copy(pos);
      avatar.object3D.rotation.copy(rot);
      if (scale) avatar.object3D.scale.copy(scale);
      scene.appendChild(avatar);
      avatar.setAttribute('persistent', 'true'); // Mark as persistent
      avatar.setAttribute('visible', 'true');
    };
    this.marker.addEventListener('markerFound', () => {
      if (this.placed) return;
      this.placed = true;
      // World transform
      let worldPos = new THREE.Vector3();
      let worldRot = new THREE.Euler();
      let worldScale = new THREE.Vector3();
      avatar.object3D.getWorldPosition(worldPos);
      avatar.object3D.getWorldQuaternion().toEuler(worldRot);
      avatar.object3D.getWorldScale(worldScale);
      this.placeInWorld(worldPos, worldRot, worldScale);
      // Also hide the marker so it doesn't re-trigger
      if(this.marker) this.marker.setAttribute('visible', 'false');
    });
  }
});

const micBtn = document.getElementById('mic');
const micEmoji = document.getElementById('mic-emoji');
const statusEl = document.getElementById('status');
const aiResponseEl = document.getElementById('ai-response');
const idle = document.getElementById('idle');
const talk = document.getElementById('talk');

function switchToIdle() {
  idle.setAttribute('visible', 'true');
  talk.setAttribute('visible', 'false');
}
function switchToTalk() {
  idle.setAttribute('visible', 'false');
  talk.setAttribute('visible', 'true');
}

function speakWithTalkAnim(text, onEnd) {
  switchToTalk();
  const msg = new SpeechSynthesisUtterance(text);
  msg.rate = 0.92;
  msg.pitch = 1.0;
  msg.onstart = () => {
    switchToTalk();
  };
  msg.onend = () => {
    switchToIdle();
    if (onEnd) onEnd();
  };
  window.speechSynthesis.cancel(); // Always stop before starting
  window.speechSynthesis.speak(msg);
}

function startListening() {
  if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
    alert('Sorry! Speech recognition not available.');
    return;
  }
  micBtn.classList.add('recording');
  micEmoji.innerText = 'ðŸ”´';
  statusEl.innerText = "Listening...";
  aiResponseEl.innerText = '';

  const recog = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
  recog.lang = "en-US";
  recog.interimResults = false;
  recog.start();

  recog.onresult = (e) => {
    const text = e.results[0][0].transcript;
    statusEl.innerText = "You: " + text;
    micEmoji.innerText = 'â³';
    micBtn.classList.remove('recording');
    askAI(text);
  };
  recog.onerror = (e) => {
    statusEl.innerText = 'Mic error. Try again.';
    micEmoji.innerText = 'ðŸŽ¤';
    micBtn.classList.remove('recording');
  };
  recog.onend = () => {
    if (micBtn.classList.contains('recording')) {
      micBtn.classList.remove('recording');
      micEmoji.innerText = 'ðŸŽ¤';
    }
  };
}

async function askAI(text) {
  statusEl.innerText = "Thinking...";
  aiResponseEl.innerText = '';
  try {
    const res = await fetch("/.netlify/functions/ask", {
      method: "POST",
      headers: {"Content-Type":"application/json"},
      body: JSON.stringify({question:text})
    });
    const data = await res.json();
    // Animate talking for each word until done
    displayTalkWithWords(data.answer);
  } catch (e) {
    statusEl.innerText = 'Error!';
    aiResponseEl.innerText = '';
    switchToIdle();
  }
}

function displayTalkWithWords(answer) {
  let words = answer.split(/\s+/);
  aiResponseEl.innerText = '';
  let cur = 0;

  function speakNextChunk() {
    if (cur >= words.length) {
      switchToIdle();
      statusEl.innerText = "";
      return;
    }
    // Speak next N (6) words for smoother animation
    let chunk = words.slice(cur, cur+6).join(' ');
    aiResponseEl.innerText += chunk + ' ';
    speakWithTalkAnim(chunk, speakNextChunk);
    cur += 6;
  }
  switchToTalk();
  speakNextChunk();
}

switchToIdle();
// --- Pinch & Rotate gesture support for persistent avatars ---
(function() {
  // Attach events to both idle and talk avatars
  ['idle','talk'].forEach(function(id) {
    let el = document.getElementById(id);
    let startDist = 0, startScale = 1, startRot = 0, baseRot = 0;
    el.addEventListener('touchstart', (e) => {
      if (e.touches.length === 2) {
        startDist = Math.hypot(
          e.touches[0].clientX - e.touches[1].clientX,
          e.touches[0].clientY - e.touches[1].clientY
        );
        startScale = el.object3D.scale.x;
        startRot = Math.atan2(
          e.touches[1].clientY - e.touches[0].clientY,
          e.touches[1].clientX - e.touches[0].clientX
        );
        baseRot = el.object3D.rotation.y;
      }
    });
    el.addEventListener('touchmove', (e) => {
      if (e.touches.length === 2) {
        const curDist = Math.hypot(
          e.touches[0].clientX - e.touches[1].clientX,
          e.touches[0].clientY - e.touches[1].clientY
        );
        let scale = Math.max(0.1, Math.min(3, startScale * (curDist / startDist)));
        el.setAttribute('scale', `${scale} ${scale} ${scale}`);
        const curRot = Math.atan2(
          e.touches[1].clientY - e.touches[0].clientY,
          e.touches[1].clientX - e.touches[0].clientX
        );
        let deltaRot = curRot - startRot;
        if (deltaRot > Math.PI) deltaRot -= 2 * Math.PI;
        if (deltaRot < -Math.PI) deltaRot += 2 * Math.PI;
        el.object3D.rotation.y = baseRot + deltaRot;
      }
    });
  });
})();
</script>
</body>
</html>

